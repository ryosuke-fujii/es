# ============================================
# ã‚»ãƒ«3: ESè¨ºæ–­ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆFlaskçµ±åˆç‰ˆï¼‰
# ============================================
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from flask import Flask, request, jsonify, render_template
import re
import threading
import time
import os

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
es_data = None
vectorizer = None
tfidf_matrix = None

# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–
# templatesãƒ•ã‚©ãƒ«ãƒ€ã‚’è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰èª­ã¿è¾¼ã‚€
base_dir = os.path.dirname(os.path.abspath(__file__))
template_dir = os.path.join(os.path.dirname(base_dir), 'templates')
app = Flask(__name__, template_folder=template_dir)

# ============================================
# ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢æ•°
# ============================================

def clean_text(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
    if pd.isna(text):
        return ""
    text = re.sub(r'\n+', ' ', str(text))
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'ç¶šãã‚’èª­ã‚€.*', '', text)
    text = re.sub(r'å•é¡Œã‚’å ±å‘Šã™ã‚‹.*', '', text)
    return text.strip()

def remove_prefix(text):
    """ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤"""
    if pd.isna(text):
        return ""
    return re.sub(r'^[^ï¼š]+ï¼š\s*', '', str(text))

def load_csv_data(csv_path):
    """CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§æ•´å½¢"""
    global es_data, vectorizer, tfidf_matrix

    print(f"\nğŸ“‚ CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­: {csv_path}")
    df = pd.read_csv(csv_path)
    print(f"âœ… {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

    print("ğŸ”§ ãƒ‡ãƒ¼ã‚¿æ•´å½¢ä¸­...")

    es_data = pd.DataFrame({
        'company_name': df['p-company-summary__name'].apply(clean_text),
        'industry': df['p-company-summary__stage-sub'].apply(remove_prefix),
        'title': df['p-company-heading-contents__title'].apply(clean_text),
        'question_1': df['u-font-light'].apply(clean_text),
        'answer_1': df['c-show-more__content'].apply(clean_text),
        'question_2': df.get('u-font-light (2)', pd.Series()).apply(clean_text),
        'answer_2': df.get('c-show-more__content (2)', pd.Series()).apply(clean_text),
        'question_3': df.get('u-font-light (3)', pd.Series()).apply(clean_text),
        'answer_3': df.get('c-show-more__content (3)', pd.Series()).apply(clean_text),
        'avg_salary': df.get('p-company-table (11)', pd.Series()).apply(clean_text),
        'employee_count': df.get('p-company-summary__stage-sub (3)', pd.Series()).apply(remove_prefix),
    })

    es_data['result_status'] = es_data['title'].apply(
        lambda x: 'å†…å®š' if 'å†…å®š' in str(x) else ('é€šé' if 'é€šé' in str(x) else 'ä¸æ˜')
    )

    es_data = es_data[es_data['result_status'].isin(['é€šé', 'å†…å®š'])]

    es_data['combined_answer'] = (
        es_data['answer_1'].fillna('') + ' ' +
        es_data['answer_2'].fillna('') + ' ' +
        es_data['answer_3'].fillna('')
    ).str.strip()

    es_data = es_data[es_data['combined_answer'].str.len() > 50]

    print(f"âœ… æœ‰åŠ¹ãªESãƒ‡ãƒ¼ã‚¿: {len(es_data)}ä»¶")

    print("ğŸ”§ TF-IDFãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­...")
    vectorizer = TfidfVectorizer(
        max_features=1000,
        min_df=2,
        max_df=0.8,
        ngram_range=(1, 2)
    )

    tfidf_matrix = vectorizer.fit_transform(es_data['combined_answer'])
    print(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Œäº†: {tfidf_matrix.shape}")

    print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:")
    print(f"  - ãƒ¦ãƒ‹ãƒ¼ã‚¯ä¼æ¥­æ•°: {es_data['company_name'].nunique()}")
    print(f"  - æ¥­ç•Œæ•°: {es_data['industry'].nunique()}")
    print(f"  - é€šéES: {(es_data['result_status'] == 'é€šé').sum()}ä»¶")
    print(f"  - å†…å®šES: {(es_data['result_status'] == 'å†…å®š').sum()}ä»¶")

def calculate_similarity(input_text, top_n=100):
    """é¡ä¼¼åº¦è¨ˆç®—"""
    input_vector = vectorizer.transform([input_text])
    similarities = cosine_similarity(input_vector, tfidf_matrix)[0]

    result = es_data.copy()
    result['similarity_score'] = similarities
    result = result.sort_values('similarity_score', ascending=False).head(top_n)

    return result

def extract_salary_numeric(salary_str):
    """çµ¦ä¸ã‹ã‚‰æ•°å€¤ã‚’æŠ½å‡º"""
    if pd.isna(salary_str):
        return None
    match = re.search(r'(\d+)ä¸‡', str(salary_str))
    if match:
        return int(match.group(1)) * 10000
    return None

def estimate_company_difficulty(row):
    """ä¼æ¥­é›£æ˜“åº¦ã‚’æ¨å®š"""
    difficulty = 0.5

    avg_salary = extract_salary_numeric(row.get('avg_salary'))
    if avg_salary:
        if avg_salary >= 8000000:
            difficulty += 0.3
        elif avg_salary >= 6000000:
            difficulty += 0.2
        elif avg_salary >= 5000000:
            difficulty += 0.1

    employee_str = str(row.get('employee_count', ''))
    if '1ä¸‡äººä»¥ä¸Š' in employee_str:
        difficulty += 0.2

    return min(difficulty, 1.0)

def calculate_match_score(similarity_score, company_difficulty, industry_match):
    """ãƒãƒƒãƒã‚¹ã‚³ã‚¢è¨ˆç®—"""
    score = (
        similarity_score * 0.6 +
        (1 - company_difficulty) * 0.2 +
        industry_match * 0.2
    )
    return min(int(score * 100), 100)

def get_top_companies(similar_es, user_industry, top_n=5):
    """TOPä¼æ¥­ã‚’é¸å‡º"""
    companies = []
    seen_companies = set()

    for _, row in similar_es.iterrows():
        company_name = row['company_name']

        if company_name in seen_companies:
            continue
        seen_companies.add(company_name)

        difficulty = estimate_company_difficulty(row)
        industry_match = 1.0 if user_industry in row['industry'] else 0.5

        match_score = calculate_match_score(
            row['similarity_score'],
            difficulty,
            industry_match
        )

        reasons = []
        if row['similarity_score'] > 0.3:
            reasons.append('ESã®å†…å®¹ãŒé¡ä¼¼')
        if industry_match == 1.0:
            reasons.append('å¿—æœ›æ¥­ç•Œã¨ä¸€è‡´')
        if difficulty < 0.6:
            reasons.append('æ¯”è¼ƒçš„é€šéã—ã‚„ã™ã„')

        reason = 'ã€'.join(reasons) if reasons else 'ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒãƒ³ã‚°'

        salary = extract_salary_numeric(row['avg_salary'])
        if salary and salary >= 7000000:
            avg_gpa = "3.2-3.8"
        elif salary and salary >= 6000000:
            avg_gpa = "3.0-3.6"
        else:
            avg_gpa = "2.8-3.4"

        companies.append({
            'name': company_name,
            'industry': row['industry'],
            'matchScore': match_score,
            'reason': reason,
            'avgGpa': avg_gpa,
            'avgSalary': row.get('avg_salary', 'ä¸æ˜'),
            'employeeCount': row.get('employee_count', 'ä¸æ˜'),
        })

        if len(companies) >= top_n:
            break

    return companies

def analyze_industry(industry):
    """æ¥­ç•Œåˆ†æ"""
    industry_data = es_data[es_data['industry'].str.contains(industry, na=False)]

    if len(industry_data) == 0:
        return {
            'passRate': 70,
            'avgApplicants': 150,
            'competition': 'ä¸­',
            'recommendations': ['æ¥­ç•Œç ”ç©¶ã‚’æ·±ã‚ã‚‹', 'ä¼æ¥­ã®ç‰¹å¾´ã‚’ç†è§£ã™ã‚‹']
        }

    pass_rate = 75
    avg_applicants = len(industry_data) * 3

    if avg_applicants > 200:
        competition = 'éå¸¸ã«é«˜'
    elif avg_applicants > 150:
        competition = 'é«˜'
    elif avg_applicants > 100:
        competition = 'ä¸­'
    else:
        competition = 'ä½'

    recommendations_map = {
        'IT': ['æŠ€è¡“ã‚¹ã‚­ãƒ«ã®è¨¼æ˜', 'ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ä½œæˆ', 'æœ€æ–°æŠ€è¡“ã®ã‚­ãƒ£ãƒƒãƒã‚¢ãƒƒãƒ—'],
        'ã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°': ['ã‚±ãƒ¼ã‚¹é¢æ¥å¯¾ç­–', 'è«–ç†çš„æ€è€ƒåŠ›ã®å¼·åŒ–', 'ãƒ•ã‚§ãƒ«ãƒŸæ¨å®šã®ç·´ç¿’'],
        'é‡‘è': ['é‡‘èçŸ¥è­˜ã®ç¿’å¾—', 'æ•°å­—ã«å¼·ã„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰', 'èª å®Ÿã•ã®ã‚¢ãƒ”ãƒ¼ãƒ«'],
        'ãƒ¡ãƒ¼ã‚«ãƒ¼': ['æŠ€è¡“åŠ›ã®è¨¼æ˜', 'é•·æœŸçš„ãªã‚­ãƒ£ãƒªã‚¢ãƒ“ã‚¸ãƒ§ãƒ³', 'ã‚‚ã®ã¥ãã‚Šã¸ã®æƒ…ç†±']
    }

    recommendations = recommendations_map.get(
        industry,
        ['æ¥­ç•Œç ”ç©¶ã‚’æ·±ã‚ã‚‹', 'ä¼æ¥­ã®ç‰¹å¾´ã‚’ç†è§£ã™ã‚‹', 'è‡ªå·±åˆ†æã‚’å¾¹åº•ã™ã‚‹']
    )

    return {
        'passRate': pass_rate,
        'avgApplicants': avg_applicants,
        'competition': competition,
        'recommendations': recommendations
    }

def analyze_gakuchika(gakuchika_text):
    """ã‚¬ã‚¯ãƒã‚«åˆ†æ"""
    strengths = []
    improvements = []

    if any(word in gakuchika_text for word in ['æ•°å€¤', 'çµæœ', 'æˆæœ', '%', 'äºº']):
        strengths.append('å…·ä½“çš„ãªæ•°å€¤ãƒ»æˆæœã®è¨˜è¼‰')

    if any(word in gakuchika_text for word in ['èª²é¡Œ', 'å•é¡Œ', 'è§£æ±º', 'æ”¹å–„']):
        strengths.append('èª²é¡Œè§£æ±ºã®ãƒ—ãƒ­ã‚»ã‚¹ãŒæ˜ç¢º')

    if len(gakuchika_text) >= 300:
        strengths.append('ååˆ†ãªåˆ†é‡ã§èª¬æ˜ã•ã‚Œã¦ã„ã‚‹')

    if not any(word in gakuchika_text for word in ['ãƒãƒ¼ãƒ ', 'å”åŠ›', 'é€£æº', 'ãƒ¡ãƒ³ãƒãƒ¼']):
        improvements.append('ãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®è¦ç´ ã‚’è¿½åŠ ')

    if not any(word in gakuchika_text for word in ['å­¦ã‚“ã ', 'å¾—ãŸ', 'æˆé•·']):
        improvements.append('å­¦ã³ã‚„æˆé•·ã®è¦ç´ ã‚’å¼·èª¿')

    if len(gakuchika_text) < 200:
        improvements.append('ã‚‚ã†å°‘ã—è©³ã—ãè¨˜è¿°ã™ã‚‹')

    return {
        'strengths': strengths if strengths else ['åŸºæœ¬çš„ãªæ§‹æˆã¯è‰¯å¥½'],
        'improvements': improvements if improvements else ['ç¾çŠ¶ã§è‰¯ã„å†…å®¹ã§ã™']
    }

# ============================================
# HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆç¾ã—ã„UIï¼‰
# ============================================

# HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯ templates/index.html ã‹ã‚‰èª­ã¿è¾¼ã¿

# ============================================
# Flaskãƒ«ãƒ¼ãƒˆ
# ============================================

@app.route('/')
def home():
    """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰UI"""
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_es():
    """ESè¨ºæ–­API"""
    try:
        data = request.get_json()

        if not data.get('gakuchika') or len(data.get('gakuchika', '')) < 100:
            return jsonify({'error': 'ã‚¬ã‚¯ãƒã‚«ã¯100æ–‡å­—ä»¥ä¸Šå…¥åŠ›ã—ã¦ãã ã•ã„'}), 400

        if not data.get('targetIndustry'):
            return jsonify({'error': 'å¿—æœ›æ¥­ç•Œã‚’é¸æŠã—ã¦ãã ã•ã„'}), 400

        similar_es = calculate_similarity(data['gakuchika'], top_n=100)
        top_companies = get_top_companies(similar_es, data['targetIndustry'], top_n=5)
        industry_analysis = analyze_industry(data['targetIndustry'])
        gakuchika_analysis = analyze_gakuchika(data['gakuchika'])

        response = {
            'matchCompanies': top_companies,
            'industryAnalysis': industry_analysis,
            'gakuchikaAnalysis': gakuchika_analysis,
            'targetCompany': data.get('targetCompany'),
            'userInfo': {
                'university': data.get('university'),
                'major': data.get('major'),
                'gpa': data.get('gpa')
            }
        }

        return jsonify(response)

    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500
